{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:01:06.251056400Z",
     "start_time": "2023-12-14T10:01:01.384226400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from llama_cpp import Llama\n",
    "import csv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class GATConvWithAttention(GATConv):\n",
    "    def forward(self, x, edge_index, edge_attr=None, size=None, return_attention_weights=True):\n",
    "        out, attention_weights = super().forward(x, edge_index, edge_attr, size, return_attention_weights)\n",
    "        return out, attention_weights\n",
    "\n",
    "class RobertaGAT(nn.Module):\n",
    "    def __init__(self, roberta_model_name, num_classes):\n",
    "        super(RobertaGAT, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
    "        self.gat = GATConvWithAttention(self.roberta.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, edge_index):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        print(sentence_embeddings, edge_index, len(sentence_embeddings), len(edge_index))\n",
    "    \n",
    "        gat_output, attention_weights = self.gat(sentence_embeddings, edge_index)\n",
    "        return F.log_softmax(gat_output, dim=1), attention_weights\n",
    "    \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoded_dataset, edge_index):\n",
    "        self.encoded_dataset = encoded_dataset\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = torch.tensor(self.encoded_dataset[idx]['label'], dtype=torch.long)\n",
    "        input_ids = torch.tensor(self.encoded_dataset[idx]['input_ids'], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(self.encoded_dataset[idx]['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        edge_index = self.edge_index[idx]\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label,  \n",
    "            'edge_index': edge_index\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:01:06.267476300Z",
     "start_time": "2023-12-14T10:01:06.256339200Z"
    }
   },
   "id": "de9d2d2ed033e6c9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llama = Llama(model_path='./llama-2-7b.Q4_K_M.gguf', embedding=True, n_ctx=2048, n_gpu_layers=30)\n",
    "\n",
    "# 图关系\n",
    "# 训练集(71251,4519)\n",
    "# 测试集合(15250,965)\n",
    "# 验证集 (16073,1028)\n",
    "def get_sentence_rel(path, num):\n",
    "    \"\"\"\n",
    "    以文章为单位，构建关系（abs_sentence-title）\n",
    "    :param path: \n",
    "    :param num: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, encoding=\"GB2312\")\n",
    "    relationship = []\n",
    "    for i in range(0, len(df['label'])):\n",
    "        if df['label'][i] == 4 and (df['label'][i + 1] == 0 or df['label'][i + 1] == 5):\n",
    "            relationship.append([i, i+1])\n",
    "            num += 1\n",
    "            continue\n",
    "        if df[\"label\"][i] != 5:\n",
    "            relationship.append([i, num])\n",
    "            relationship.append([i, i+1])\n",
    "\n",
    "    return relationship\n",
    "\n",
    "def get_abstract_embedding(path, start, type):\n",
    "    \"\"\"\n",
    "    Llama编码获取摘要embedding。处理结果为[[][]]\n",
    "    :param type: \n",
    "    :param path: \n",
    "    :param start: \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, encoding='GB2312')\n",
    "    abstract = ''\n",
    "    for i in range(start, len(df['label'])):\n",
    "        try:\n",
    "            abstract += df['text'][i]\n",
    "            if df['label'][i] == 4 and df['label'][i + 1] == 0:\n",
    "                abstract_embedding = llama.create_embedding(input=abstract).get('data')[0].get('embedding')\n",
    "                np.save(f\"./temp/abstract_embedding{i}.npy\", abstract_embedding)\n",
    "                with open(f'./data/abstract_embedding_{type}.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([abstract, f'abstract_embedding{i}.npy'])\n",
    "                abstract = ''\n",
    "        finally:\n",
    "            continue\n",
    "    tmp = []   \n",
    "    files = os.listdir(\"./temp\", )\n",
    "    # 获取每个文件的完整路径\n",
    "    full_paths = [os.path.join(\"./temp\", file) for file in files]\n",
    "    # 按创建时间对文件进行排序\n",
    "    sorted_files = sorted(full_paths, key=os.path.getctime)\n",
    "    for file in sorted_files:\n",
    "        if file.endswith('.npy'):\n",
    "            tmp.append(np.load(f'{file}', allow_pickle=True))\n",
    "    np.array(tmp)\n",
    "    np.save(f'./data/abstract_embedding_{type}.npy', tmp)\n",
    "\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return cosine_similarity([a, b])[0][1]\n",
    "\n",
    "def get_paper_rel(array, num):\n",
    "    \"\"\"\n",
    "    获取文章直接的关系（title-title）\n",
    "    :param array: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    rels = []\n",
    "    for i in range(0, len(array)):\n",
    "        for j in range(i+1, len(array)):\n",
    "                cos = cos_sim(array[i], array[j])\n",
    "                if cos >= 0.93:\n",
    "                   rels.append([num + i, num + j])\n",
    "    return rels \n",
    "\n",
    "def get_edge_index(sen_rel, abs_rel):\n",
    "    \"\"\"\n",
    "    按节点，构建图关系\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('data/test.csv')\n",
    "    rels = []\n",
    "    for i in range(len(df['label'])):\n",
    "        rel = []\n",
    "        for j in (sen_rel + abs_rel):\n",
    "            if i in j:\n",
    "                rel.append(j)            \n",
    "        rels.append(rel)\n",
    "    return rels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:01:06.482392300Z",
     "start_time": "2023-12-14T10:01:06.267476300Z"
    }
   },
   "id": "337f5c87ce2eea22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get_abstract_embedding(path='data/test.csv', start=0, type='test')\n",
    "# get_abstract_embedding(path='data/validation.csv', start=0, type='valid')\n",
    "# get_abstract_embedding(path='data/train.csv', start=0, type='train')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-14T03:03:12.484596600Z"
    }
   },
   "id": "84bde42d28abd632"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 加载数据集\n",
    "dataset_train = load_dataset('csv', data_files='data/train.csv', encoding='utf-8')\n",
    "dataset_test = load_dataset('csv', data_files='data/test.csv', encoding='utf=8')\n",
    "dataset_valid = load_dataset('csv', data_files='data/validation.csv', encoding='utf-8')\n",
    "dataset = DatasetDict({'train': dataset_train, 'test': dataset_test, 'validation': dataset_valid})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:01:17.068944300Z",
     "start_time": "2023-12-14T10:01:12.492486100Z"
    }
   },
   "id": "14b5c2fea9293287"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# 获取边关系\n",
    "# 训练集合边关系\n",
    "train_sen_rel = get_sentence_rel(path='data/train.csv', num=71251)\n",
    "train_abs_rel = np.load('data/abstract_embedding_train.npy')\n",
    "train_paper_rel = get_paper_rel(train_abs_rel, num=71251)\n",
    "train_rel = get_edge_index(train_sen_rel, train_paper_rel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T07:49:48.683911500Z",
     "start_time": "2023-12-14T07:49:35.578076600Z"
    }
   },
   "id": "f26eb199a8905764"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 测试集合边关系\n",
    "test_sen_rel = get_sentence_rel(path='data/test.csv', num=15250)\n",
    "test_abs_rel = np.load('data/abstract_embedding_test.npy')\n",
    "test_paper_rel = get_paper_rel(test_abs_rel, num=15250)\n",
    "test_rel = get_edge_index(test_sen_rel, test_paper_rel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:02:53.637529600Z",
     "start_time": "2023-12-14T10:01:17.072177400Z"
    }
   },
   "id": "fdce53d6e76f9c63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 验证集合边关系\n",
    "valid_sen_rel = get_sentence_rel(path='data/validation.csv', num=16073)\n",
    "valid_abs_rel = np.load('data/abstract_embedding_validation.npy')\n",
    "valid_paper_rel = get_paper_rel(valid_abs_rel, num=16073)\n",
    "valid_rel = get_edge_index(valid_sen_rel, valid_paper_rel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4d2835a6a6109a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/16214 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f15482a111db49028cccf587b4f0a6cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/17100 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d41c796d1fb45a39d715ce061200c35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "def encode_batch(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=2048, return_tensors=\"pt\")\n",
    "\n",
    "dataset = {split: dataset[split].map(encode_batch, batched=True) for split in dataset.keys()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:03:02.806215Z",
     "start_time": "2023-12-14T10:02:53.640682800Z"
    }
   },
   "id": "b8943632c32c1976"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    \n",
    "    cum_num_nodes = 0  # 累积节点数\n",
    "    edge_index = []\n",
    "    for item in batch:\n",
    "        # 如果您确定每个样本的edge_index总是非空，可以直接处理\n",
    "        edge_index_tensor = torch.tensor(item['edge_index'], dtype=torch.long) if isinstance(item['edge_index'], list) else item['edge_index']\n",
    "\n",
    "        # 调整edge_index的节点索引\n",
    "        edge_index_adjusted = edge_index_tensor + cum_num_nodes\n",
    "        edge_index.append(edge_index_adjusted.t())  # 转置以确保两行\n",
    "\n",
    "        # 更新累积节点数\n",
    "        num_nodes = item['input_ids'].size(0)  # 假设input_ids的长度等于节点数\n",
    "        cum_num_nodes += num_nodes\n",
    "\n",
    "    # 合并edge_index\n",
    "    edge_index = torch.cat(edge_index, dim=1)\n",
    "    print(edge_index)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels,\n",
    "        'edge_index': edge_index\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:03:02.823720300Z",
     "start_time": "2023-12-14T10:03:02.811907200Z"
    }
   },
   "id": "1978f7ff6407ccb4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# train_data_split = dataset['train'] \n",
    "test_data_split = dataset['test']\n",
    "# valid_data_split = dataset['validation']\n",
    "# train_dataset = CustomDataset(train_data_split['train'], train_rel)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = CustomDataset(test_data_split['train'], test_rel)\n",
    "# print(len(test_rel))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "# print(len(test_loader))\n",
    "# valid_dataset = CustomDataset(valid_data_split['train'], train_rel)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:03:02.824718200Z",
     "start_time": "2023-12-14T10:03:02.814997100Z"
    }
   },
   "id": "1af521403b8b42d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaGAT(\"roberta-base\", num_classes=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 10\n",
    "\n",
    "writer = SummaryWriter('log/robert-gat')\n",
    "\n",
    "def validate(model, valid_loader, criterion, device):\n",
    "    model.eval() \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for batch in valid_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            edge_index = batch['edge_index'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            output, _ = model(input_ids, attention_mask, edge_index)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6092069c0e03ef26"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10304, 10305, 10305,  7439,  7440,  7440, 13841, 13842, 13842,  5588,\n",
      "          5589,  5590,  5591,  5592,  5593,  5594,  5595,  5596,  5597,  5598,\n",
      "          5599,  5600,  5601,  5602,  5603,  5604,  5711,  5712,  5712, 11310,\n",
      "         11311, 11311, 10214, 10215, 10215,  2726,  2727,  2727,  3340,  3341,\n",
      "          3341, 14335, 14336, 14336,  7171,  7172,  7172, 14528, 14529, 14529,\n",
      "          8325,  8326,  8326, 10706, 10707, 10707,  3254,  3255,  8571,  8572,\n",
      "          8572, 11403, 11404, 11404, 10246, 10247, 10247,  5762,  5763,  5763,\n",
      "         17848, 17849, 17849, 12417, 12418,  9393,  9394,  9394, 10705, 10706,\n",
      "         10707, 10708, 10709, 10710, 10711, 10712, 10713, 10714, 10715, 10716,\n",
      "         10717, 10718, 10719, 10720, 10721, 14214, 14215, 14216, 14217, 14218,\n",
      "         14219, 14220, 14221, 14222, 14223, 14224, 14225, 14226, 14227, 14228,\n",
      "          4816,  4817, 15567, 15568, 15568,  8192,  8193,  8193, 17717, 17718,\n",
      "         17718,  8119,  8120,  8120, 10105, 10106, 10106, 18006, 18007, 18007,\n",
      "         14527, 14528],\n",
      "        [10305, 15902, 10306,  7440, 15934,  7441, 13842, 16516, 13843, 16230,\n",
      "         16230, 16230, 16230, 16230, 16230, 16230, 16230, 16230, 16230, 16230,\n",
      "         16230, 16230, 16230, 16230, 16230, 16230,  5712, 16388,  5713, 11311,\n",
      "         16916, 11312, 10215, 17058, 10216,  2727, 16752,  2728,  3341, 16922,\n",
      "          3342, 14336, 17751, 14337,  7172, 17408,  7173, 14529, 18031, 14530,\n",
      "          8326, 17744,  8327, 10707, 18112, 10708,  3255,  3256,  8572, 18346,\n",
      "          8573, 11404, 18689, 11405, 10247, 18782, 10248,  5763, 18675,  5764,\n",
      "         17849, 19586, 17850, 12418, 12419,  9394, 19493,  9395, 19734, 19734,\n",
      "         19734, 19734, 19734, 19734, 19734, 19734, 19734, 19734, 19734, 19734,\n",
      "         19734, 19734, 19734, 19734, 19734, 20104, 20104, 20104, 20104, 20104,\n",
      "         20104, 20104, 20104, 20104, 20104, 20104, 20104, 20104, 20104, 20104,\n",
      "          4817,  4818, 15568, 20554, 15569,  8193, 20294,  8194, 17718, 21043,\n",
      "         17719,  8120, 20541,  8121, 10106, 20818, 10107, 18007, 21495, 18008,\n",
      "         14528, 14529]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m test_loader:\n\u001B[1;32m----> 5\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      6\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m     edge_index \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        edge_index = batch['edge_index'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, attention_mask, edge_index)\n",
    "        loss = criterion(output, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    writer.add_scalar('Training loss', avg_loss, epoch)\n",
    "    # avg_val_loss, val_accuracy = validate(model, valid_loader, criterion, device)\n",
    "    # writer.add_scalar('Validation Loss', avg_val_loss, epoch)\n",
    "    # writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(test_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T10:54:06.937273600Z",
     "start_time": "2023-12-14T10:54:06.853038600Z"
    }
   },
   "id": "cb5ba0e5a56a2b99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c177ced73731d7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
