text,label
"Artificial Intelligence (AI) use in automated Electrocardiogram (ECG) classification has continuously attracted the research community's interest, motivated by their promising results.",0
"Despite their great promise, limited attention has been paid to the robustness of their results, which is a key element for their implementation in clinical practice.	Significance",0
"Uncertainty Quantification (UQ) is critical for trustworthy and reliable AI, particularly in safety-critical domains such as medicine.	Significance",0
"Estimating uncertainty in Machine Learning (ML) model predictions has been extensively used for Out-of-Distribution (OOD) detection under single-label tasks.	Content",1
"However, the use of UQ methods in multi-label classification remains underexplored.	Content",1
"This study goes beyond developing highly accurate models comparing five uncertainty quantification methods using the same Deep Neural Network (DNN) architecture across various validation scenarios, including internal and external validation as well as OOD detection, taking multi-label ECG classification as the example domain.	Content",1
"We show the importance of external validation and its impact on classification performance, uncertainty estimates quality, and calibration.	Result",2
"Ensemble-based methods yield more robust uncertainty estimations than single network or stochastic methods.	Result",2
"Although current methods still have limitations in accurately quantifying uncertainty, particularly in the case of dataset shift, incorporating uncertainty estimates with a classification with a rejection option improves the ability to detect such changes.	Conclusion",3
"Moreover, we show that using uncertainty estimates as a criterion for sample selection in an active learning setting results in greater improvements in classification performance compared to random sampling.	Conclusion",3
"Counterfactual explanations highlight actionable knowledge which helps to understand how a machine learning model outcome could be altered to a more favourable outcome.	Significance",0
"Understanding actionable corrections in source code analysis can be critical to proactively mitigate security attacks that are caused by known vulnerabilities.	Significance",0
"In this paper, we present the DisCERN explainer for discovering counterfactuals for code vulnerability correction.	Content",1
"Given a vulnerable code segment, DisCERN finds counterfactual (i.e., non-vulnerable) code segments and recommends actionable corrections.	Content",1
"DisCERN uses feature attribution knowledge to identify potentially vulnerable code statements.	Content",1
"Subsequently, it applies a substitution-focused correction, suggesting suitable fixes by analysing the nearest-unlike neighbour.	Content",1
"A user study evaluated the utility of counterfactuals for vulnerability detection and correction compared to more commonly used feature attribution explainers.	Result",2
"The study revealed that counterfactuals foster positive shifts in mental models, effectively guiding users towards making vulnerability corrections.	Result",2
"Furthermore, counterfactuals significantly reduced the cognitive load when detecting and correcting vulnerabilities in complex code segments.	Result",2
"Despite the benefits of counterfactual explanations, the user study showed that feature attribution explanations are still more widely accepted than counterfactuals, possibly due to the greater familiarity with the former and the novelty of the latter.	Conclusion",3
"These findings encourage further research and development into counterfactual explanations, as they demonstrate the potential for acceptability over time among developers as a reliable resource for both coding and training.	Conclusion",3
